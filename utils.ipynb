{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd242823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import itertools\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d9cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f801a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/34950201/pycharm-print-end-r-statement-not-working\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  # stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode = 'w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1):\n",
    "        if '\\r' in message: is_file = 0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            # time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05789947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path, model_name):\n",
    "#     if not os.path.exists(save_path):\n",
    "#         os.makedirs(save_path)\n",
    "    filename = os.path.join(save_path, model_name + '.pth.tar')\n",
    "    torch.save({'state_dict': model.state_dict(), }, filename)\n",
    "    \n",
    "    # if is_best:\n",
    "    #     best_filename = os.path.join(save_path, model_name + '_best_model.pth.tar')\n",
    "    #     shutil.copyfile(filename, best_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, load_path, model_name):\n",
    "    if not os.path.exists(load_path):\n",
    "        os.makedirs(load_path)\n",
    "    filename = os.path.join(load_path, model_name + '.pth.tar')\n",
    "    model.load_state_dict(torch.load(filename)['state_dict'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed every 10 epochs\"\"\"\n",
    "    # lr = args.lr * (0.5 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * (0.3 ** (epoch // 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68ef534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Handles PyTorch x Numpy seeding issues.\n",
    "    Args:\n",
    "        worker_id (int): Id of the worker.\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5f488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a57da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9159f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, rank, rank_mask):\n",
    "        # loss = (inputs - rank) ** 2 * rank_mask\n",
    "        # .abs(); Computes the absolute value of each element in input.\n",
    "        loss = torch.abs(inputs - rank) * rank_mask\n",
    "            # loss.shape => torch.Size([1, 509])\n",
    "            # torch.sum(loss, dim=1).shape, torch.sum(rank_mask, dim=1).shape => torch.Size([1]) torch.Size([1])\n",
    "        loss = torch.sum(loss, dim=1) / torch.sum(rank_mask, dim=1)\n",
    "            # loss.shape => torch.Size([1])\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50623d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBCELoss(nn.Module):\n",
    "    def __init__(self, class_weight=False):\n",
    "        super().__init__()\n",
    "        self.class_weight = class_weight\n",
    "\n",
    "    def forward(self, inputs, targets, mask, sample_weight=None):\n",
    "        # print(inputs)\n",
    "        # inputs = inputs[:,:targets.shape[1]]\n",
    "        bce1 = F.binary_cross_entropy(inputs, torch.ones_like(inputs), reduction='none')\n",
    "        bce2 = F.binary_cross_entropy(inputs, torch.zeros_like(inputs), reduction='none')\n",
    "        bce = 1 * bce1 * targets + bce2 * (1 - targets)\n",
    "        # mask = torch.where(targets >= 0, torch.ones_like(bce), torch.zeros_like(bce))\n",
    "        bce = bce * mask\n",
    "        # print(bce)\n",
    "        #         if sample_weight is not None:\n",
    "        #             bce = bce * sample_weight.unsqueeze(1)\n",
    "        loss = torch.sum(bce, dim=1) / torch.sum(mask, dim=1)\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04695eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=1., emb_name='emb'):\n",
    "        # emb_name This parameter should be replaced with the parameter name of embedding in your model\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name and param.grad is not None:\n",
    "                # print(name, param)\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / max(norm, 0.001)\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='emb'):\n",
    "        # emb_name This parameter should be replaced with the parameter name of embedding in your model\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name and param.grad is not None:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/code/ryanholbrook/competition-metric-kendall-tau-correlation\n",
    "# Actually O(N^2), but fast in practice for our data\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):  # O(N)\n",
    "        j = bisect(sorted_so_far, u)  # O(log N)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)  # O(N)\n",
    "    return inversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0  # total inversions in predicted ranks across all instances\n",
    "    total_2max = 0  # maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        assert len(gt) == len(pred)\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(df, masks, rank_pred, code_df_valid, data_dir):\n",
    "    #     df['cell_id2'] = [[y[i] for i in range(len(x)) if x[i] == 1] for x, y in\n",
    "    #                           zip(df['cell_type'].values, df['cell_id'].values)]\n",
    "    df['cell_id2'] = df['cell_id']\n",
    "    df = df[['id', 'cell_id2']].explode('cell_id2')\n",
    "        # df.head(2) =>\n",
    "        #                    id  cell_id2\n",
    "        # 0      0001bdd4021779  3fdc37be\n",
    "        # 0      0001bdd4021779  073782ca\n",
    "\n",
    "        # pd.isnull(df['cell_id2']) =>\n",
    "        # 0       False\n",
    "        # 0       False\n",
    "        #         ...\n",
    "        # Name: cell_id2, Length: 52282, dtype: bool\n",
    "    df = df[~pd.isnull(df['cell_id2'])]\n",
    "        # rank_pred.flatten()[0:10]\n",
    "        # [-0.01354445  0.06333275  0.09860276  0.12805334  0.04778271  0.03880716 ...\n",
    "        \n",
    "        # masks.flatten()[0:10] =>\n",
    "        # [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "    preds = rank_pred.flatten()[np.where(masks.flatten() == 1)]        \n",
    "        # preds.flatten()[0:10]\n",
    "        # [-0.01354445 -0.01515285 -0.01671559  0.00495259 -0.02522139 -0.02115827\n",
    "    df['rank2'] = preds\n",
    "        # df.groupby(by=['id', 'cell_id2'], as_index=False)['rank2'].head(2) => \n",
    "        # 0      -0.013544\n",
    "        # 0      -0.015153\n",
    "        #         ...\n",
    "        # Name: rank2, Length: 47718, dtype: float64\n",
    "\n",
    "        # ( showing all rows of id 0001bdd4021779 ), df.head(10) => \n",
    "        #                id  cell_id2     rank2\n",
    "        # 0  0001bdd4021779  3fdc37be -0.013544\n",
    "        # 0  0001bdd4021779  073782ca -0.015153\n",
    "        # 0  0001bdd4021779  8ea7263c -0.016716\n",
    "        # 0  0001bdd4021779  80543cd8  0.004953\n",
    "        # 0  0001bdd4021779  38310c80 -0.025221\n",
    "        # 0  0001bdd4021779  073e27e5 -0.021158\n",
    "        # 0  0001bdd4021779  015d52a4  0.042571\n",
    "        # 0  0001bdd4021779  ad7679ef  0.043002\n",
    "        # 0  0001bdd4021779  07c52510 -0.010163\n",
    "        # 0  0001bdd4021779  0a1a7a39  0.006047\n",
    "        # 0  0001bdd4021779  0bcd3fef -0.015030\n",
    "        # 0  0001bdd4021779  7fde4f04  0.083458\n",
    "        # 0  0001bdd4021779  58bf360b  0.093474\n",
    "    df = df.groupby(by=['id', 'cell_id2'], as_index=False)['rank2'].agg('mean')\n",
    "        # df.groupby(by=['id', 'cell_id2'], as_index=True)['rank2'].agg('mean').head(10) =>\n",
    "        # id              cell_id2\n",
    "        # 0001bdd4021779  015d52a4    0.042571\n",
    "        #                 073782ca   -0.015153\n",
    "        #                 073e27e5   -0.021158\n",
    "        #                 07c52510   -0.010163\n",
    "        #                 0a1a7a39    0.006047\n",
    "        #                 0bcd3fef   -0.015030\n",
    "        #                 38310c80   -0.025221\n",
    "        #                 3fdc37be   -0.013544\n",
    "        #                 58bf360b    0.093474\n",
    "        #                 7fde4f04    0.083458\n",
    "        #                 80543cd8    0.004953\n",
    "        #                 8ea7263c   -0.016716\n",
    "        #                 ad7679ef    0.043002\n",
    "        # Name: rank2, dtype: float64    \n",
    "        \n",
    "        # ( showing all rows of id 0001bdd4021779 ), df.head(10) =>\n",
    "        #                 id  cell_id2     rank2\n",
    "        # 0   0001bdd4021779  015d52a4  0.042571\n",
    "        # 1   0001bdd4021779  073782ca -0.015153\n",
    "        # 2   0001bdd4021779  073e27e5 -0.021158\n",
    "        # 3   0001bdd4021779  07c52510 -0.010163\n",
    "        # 4   0001bdd4021779  0a1a7a39  0.006047\n",
    "        # 5   0001bdd4021779  0bcd3fef -0.015030\n",
    "        # 6   0001bdd4021779  38310c80 -0.025221\n",
    "        # 7   0001bdd4021779  3fdc37be -0.013544\n",
    "        # 8   0001bdd4021779  58bf360b  0.093474\n",
    "        # 9   0001bdd4021779  7fde4f04  0.083458\n",
    "        \n",
    "    df.rename(columns={'cell_id2': 'cell_id'}, inplace=True)\n",
    "        # code_df_valid.head(2) =>\n",
    "        #                id   cell_id     rank2\n",
    "        # 0  00001756c60be8  1862f0a6  0.033333\n",
    "        # 1  00001756c60be8  2a9e43d6  0.066667\n",
    "    code_df_valid_tmp = code_df_valid[code_df_valid['id'].isin(df['id'])]\n",
    "        # code_df_valid_tmp.head(2) =>    \n",
    "        #                  id   cell_id     rank2\n",
    "        # 102  0001bdd4021779  3fdc37be  0.090909\n",
    "        # 103  0001bdd4021779  073782ca  0.181818    \n",
    "    code_df_valid_tmp['rank3'] = code_df_valid_tmp.groupby(by=['id'])['rank2'].rank(ascending=True, method='first')\n",
    "        # code_df_valid_tmp.head(3) =>\n",
    "        #                  id   cell_id     rank2  rank3\n",
    "        # 102  0001bdd4021779  3fdc37be  0.090909    1.0\n",
    "        # 103  0001bdd4021779  073782ca  0.181818    2.0\n",
    "        # 104  0001bdd4021779  8ea7263c  0.272727    3.0\n",
    "        \n",
    "    # df is much larger dataframe than code_df_valid_tmp, thus we find many empty values in ['rank3'] -\n",
    "    # - column of \"code_df_valid_tmp\".\n",
    "    tmp = code_df_valid_tmp[['id', 'cell_id', 'rank3']].merge(df, how='inner', on=['id', 'cell_id'])\n",
    "        # tmp.head(3) =>    \n",
    "        #                id   cell_id  rank3     rank2\n",
    "        # 0  0001bdd4021779  3fdc37be    1.0 -0.013544\n",
    "        # 1  0001bdd4021779  073782ca    2.0 -0.015153\n",
    "        # 2  0001bdd4021779  8ea7263c    3.0 -0.016716    \n",
    "        \n",
    "    tmp['rank4'] = tmp.groupby(by=['id'])['rank2'].rank(ascending=True, method='first')\n",
    "        # tmp.head(15) =>    \n",
    "        #                 id   cell_id  rank3     rank2  rank4\n",
    "        # 0   0001bdd4021779  3fdc37be    1.0 -0.013544    6.0\n",
    "        # 1   0001bdd4021779  073782ca    2.0 -0.015153    4.0\n",
    "        # 2   0001bdd4021779  8ea7263c    3.0 -0.016716    3.0\n",
    "        # 3   0001bdd4021779  80543cd8    4.0  0.004953    8.0\n",
    "        # 4   0001bdd4021779  38310c80    5.0 -0.025221    1.0\n",
    "        # 5   0001bdd4021779  073e27e5    6.0 -0.021158    2.0\n",
    "        # 6   0001bdd4021779  015d52a4    7.0  0.042571   10.0\n",
    "        # 7   0001bdd4021779  ad7679ef    8.0  0.043002   11.0\n",
    "        # 8   0001bdd4021779  07c52510    9.0 -0.010163    7.0\n",
    "        # 9   0001bdd4021779  0a1a7a39   10.0  0.006047    9.0\n",
    "        # 10  0001bdd4021779  0bcd3fef   11.0 -0.015030    5.0\n",
    "        # 11  0002115f48f982  18281c6c    1.0 -0.024155    3.0\n",
    "        # 12  0002115f48f982  e3b6b115    2.0 -0.072884    2.0\n",
    "\n",
    "    tmp = tmp[['id', 'cell_id', 'rank3']].merge(tmp[['id', 'rank4', 'rank2']].rename(columns={'rank4': 'rank3'}),\n",
    "                                                how='inner', on=['id', 'rank3'])\n",
    "        # tmp.head(15) =>\n",
    "        #                 id   cell_id  rank3     rank2\n",
    "        # 0   0001bdd4021779  3fdc37be    1.0 -0.025221\n",
    "        # 1   0001bdd4021779  073782ca    2.0 -0.021158\n",
    "        # 2   0001bdd4021779  8ea7263c    3.0 -0.016716\n",
    "        # 3   0001bdd4021779  80543cd8    4.0 -0.015153\n",
    "        # 4   0001bdd4021779  38310c80    5.0 -0.015030\n",
    "        # 5   0001bdd4021779  073e27e5    6.0 -0.013544\n",
    "        # 6   0001bdd4021779  015d52a4    7.0 -0.010163\n",
    "        # 7   0001bdd4021779  ad7679ef    8.0  0.004953\n",
    "        # 8   0001bdd4021779  07c52510    9.0  0.006047\n",
    "        # 9   0001bdd4021779  0a1a7a39   10.0  0.042571\n",
    "        # 10  0001bdd4021779  0bcd3fef   11.0  0.043002\n",
    "        # 11  0002115f48f982  18281c6c    1.0 -0.125229\n",
    "        # 12  0002115f48f982  e3b6b115    2.0 -0.072884\n",
    "        # 13  0002115f48f982  4a044c54    3.0 -0.024155\n",
    "        # 14  0002115f48f982  365fe576    4.0 -0.014178\n",
    "        \n",
    "    tmp = tmp[['id', 'cell_id', 'rank2']]\n",
    "    df = df.merge(tmp[['id', 'cell_id', 'rank2']].rename(columns={'rank2': 'rank3'}), how='left', on=['id', 'cell_id'])\n",
    "    # now, ['rank3'] contains predictions for only code cells.\n",
    "    # ['rank2'] contains predictions for both cell types.\n",
    "        # df.head(4) =>\n",
    "        #                id   cell_id     rank2     rank3\n",
    "        # 0  0001bdd4021779  015d52a4  0.042571 -0.010163\n",
    "        # 1  0001bdd4021779  073782ca -0.015153 -0.021158\n",
    "        # 2  0001bdd4021779  073e27e5 -0.021158 -0.013544\n",
    "        # 3  0001bdd4021779  07c52510 -0.010163  0.006047        \n",
    "        \n",
    "    \n",
    "    df['rank2'] = np.where(pd.isnull(df['rank3']), df['rank2'], df['rank3']) \n",
    "\n",
    "    # df = pd.concat([df[['id', 'cell_id', 'rank2']], code_df_valid_tmp]).reset_index(drop=True)\n",
    "    \n",
    "    # sort ['id'] and then within each id sort ['rank2'].\n",
    "    df = df.sort_values(by=['id', 'rank2'], ascending=True)\n",
    "        # df.head(4) =>\n",
    "        #                 id   cell_id     rank2     rank3\n",
    "        # 7   0001bdd4021779  3fdc37be -0.025221 -0.025221\n",
    "        # 1   0001bdd4021779  073782ca -0.021158 -0.021158\n",
    "        # 11  0001bdd4021779  8ea7263c -0.016716 -0.016716\n",
    "        # 10  0001bdd4021779  80543cd8 -0.015153 -0.015153\n",
    "        \n",
    "    res = df.groupby(by=['id'], sort=False, as_index=False)['cell_id'].agg(list)\n",
    "        # res.head(2) =>\n",
    "        #                id                                            cell_id\n",
    "        # 0  0001bdd4021779  [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310...\n",
    "        # 1  0002115f48f982  [18281c6c, e3b6b115, 4a044c54, 365fe576, a3188...\n",
    "    train_orders = pd.read_csv(data_dir + 'train_orders.csv')\n",
    "    train_orders['cell_order'] = train_orders['cell_order'].str.split()      \n",
    "    res = res.merge(train_orders, how='left', on='id')\n",
    "        #                id                                            cell_id                                          cell_order\n",
    "        # 0  0001bdd4021779  [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310...   [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310... \n",
    "        # 1  0002115f48f982  [18281c6c, e3b6b115, 4a044c54, 365fe576, a3188...   [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe... \n",
    "\n",
    "    score = kendall_tau(res['cell_order'], res['cell_id'])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09347ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_name, res = '../input/'):    \n",
    "    if model_name in ['distilroberta-base', 'roberta-base', 'roberta-large']:\n",
    "        res += 'roberta-transformers-pytorch/' + model_name\n",
    "    elif model_name in ['bart-base', 'bart-large']:\n",
    "        res += 'bartbase' if model_name == 'bart-base' else 'bartlarge'\n",
    "        res += '/'\n",
    "    elif model_name in ['deberta-base', 'deberta-large', 'deberta-v2-xlarge', 'deberta-v2-xxlarge']:\n",
    "        res += 'deberta/' + model_name.replace('deberta-', '')\n",
    "    elif model_name in ['deberta-v3-large']:\n",
    "        res += 'deberta-v3-large/' + model_name\n",
    "    elif model_name in ['electra-base', 'electra-large']:\n",
    "        res += 'electra/' + model_name + '-discriminator'\n",
    "    elif 'albert' in model_name:\n",
    "        res += 'pretrained-albert-pytorch/' + model_name\n",
    "    elif model_name == 'deberta-v3-base':\n",
    "        res += 'deberta-v3-base/' + model_name\n",
    "    elif model_name == 'deberta-v3-large':\n",
    "        res += 'deberta-v3-large/' + model_name\n",
    "    elif model_name == 'funnel-large':\n",
    "        res += 'funnel-large/'\n",
    "    elif model_name == 'xlnet-base':\n",
    "        res += 'xlnet-pretrained/xlnet-pretrained/'\n",
    "    elif model_name == 'deberta-base-mnli':\n",
    "        res += 'huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/'\n",
    "    elif model_name == 'deberta-xlarge':\n",
    "        res += 'huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/'\n",
    "    elif model_name == 'codebert-base':\n",
    "        res += 'codebert-base/codebert-base/'\n",
    "    elif model_name == 'CodeBERTa-small-v1':\n",
    "        res += 'huggingface-code-models/CodeBERTa-small-v1/'\n",
    "    elif model_name == 'mdeberta-v3-base':\n",
    "        res += 'mdeberta-v3-base/'\n",
    "    else:\n",
    "        raise ValueError(model_name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209624cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ab9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
